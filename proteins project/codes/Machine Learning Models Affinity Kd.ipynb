{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31281642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, LogisticRegression, Perceptron\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30924b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_simple(data):\n",
    "  model_checkpoint = \"facebook/esm2_t12_35M_UR50D\"\n",
    "  from transformers import AutoTokenizer\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "  y=data.iloc[:, -1]\n",
    "  print(\"labels:\", y.shape)\n",
    "# before alignment\n",
    "  fingerprint = []\n",
    "  sequence = []\n",
    "  for i in range(len(data)):\n",
    "    compound, protein, interaction = data.iloc[i, :]\n",
    "\n",
    "    mol = Chem.AddHs(Chem.MolFromSmiles(compound))\n",
    "    fingerprint.append(np.array([int(i) for i in AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024, useChirality=True).ToBitString()]))\n",
    "    sequence.append( np.array(tokenizer(protein,padding='max_length')['input_ids']))\n",
    "# alignments\n",
    "  sequence =pd.DataFrame(sequence)\n",
    "  sequence= sequence.fillna(0)\n",
    "# after alignments, combine different parts of data\n",
    "  fingerprint=pd.DataFrame(fingerprint)\n",
    "  X = pd.concat([fingerprint, sequence], axis=1)\n",
    "  print(\"dataset:\", X.shape)\n",
    "  print(\"Number of positive/negative labels:\", y.value_counts())\n",
    "  return X, y\n",
    "\n",
    "def token_poly(data):\n",
    "  y=data.iloc[:, -1]\n",
    "  print(\"labels:\", y.shape)\n",
    "  fingerprint = []\n",
    "  for i in range(len(data)):\n",
    "    compound, protein, interaction = data.iloc[i, :]\n",
    "    mol = Chem.AddHs(Chem.MolFromSmiles(compound))\n",
    "    fingerprint.append(np.array([int(i) for i in AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=64, useChirality=True).ToBitString()]))\n",
    "# after alignments\n",
    "  X=pd.DataFrame(fingerprint)\n",
    "  print(\"dataset:\", X.shape)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c723890",
   "metadata": {},
   "source": [
    "### Future Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b36ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply different protein tokenization for different models\n",
    "ESM_models = ['facebook/esm2_t48_15B_UR50D', 'facebook/esm2_t36_3B_UR50D', 'facebook/esm2_t33_650M_UR50D', 'facebook/esm2_t30_150M_UR50D', 'facebook/esm2_t12_35M_UR50D', 'facebook/esm2_t6_8M_UR50D']\n",
    "\n",
    "# apply different fingerprint algorithms for the compounds \n",
    "fpgen1 = AllChem.GetRDKitFPGenerator()\n",
    "fpgen2 = AllChem.GetAtomPairGenerator()\n",
    "fpgen3 = AllChem.GetMorganGenerator(radius=2)\n",
    "\n",
    "# fairness: with different ratios of positive and negative samples for CPIs prediction.\n",
    "#dataset_0 = dataset.['interaction' = 0][0:1000]\n",
    "#dataset_1 = dataset.['interaction' = 1][0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e5ce9",
   "metadata": {},
   "source": [
    "## Supervised Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9356bb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rabin badree\\OneDrive\\Documents\\badreeRoziena\\machineLearning\\project\\github\\data\\csv\n"
     ]
    }
   ],
   "source": [
    "# change the directory to that of the CSV files.\n",
    "\n",
    "current = os.getcwd()\n",
    "os.chdir('../data/csv/')\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd870aa4",
   "metadata": {},
   "source": [
    "### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a558dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: (3811,)\n",
      "dataset: (3811, 2510)\n",
      "Number of positive/negative labels: 5.920819    31\n",
      "6.000000    31\n",
      "5.698970    29\n",
      "5.958607    28\n",
      "5.886057    27\n",
      "            ..\n",
      "5.075905     1\n",
      "6.990911     1\n",
      "8.489455     1\n",
      "9.494850     1\n",
      "6.417937     1\n",
      "Name: 2, Length: 1477, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 500 out of 500 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge Linear Regression</td>\n",
       "      <td>2.285426</td>\n",
       "      <td>-1.132574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso Linear Regression</td>\n",
       "      <td>1.367706</td>\n",
       "      <td>0.236242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine (Gaussian RBF)</td>\n",
       "      <td>1.421241</td>\n",
       "      <td>0.175282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.184066</td>\n",
       "      <td>0.427571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1.259279</td>\n",
       "      <td>0.352538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model      RMSE  R2 Score\n",
       "0                Ridge Linear Regression  2.285426 -1.132574\n",
       "1                Lasso Linear Regression  1.367706  0.236242\n",
       "2  Support Vector Machine (Gaussian RBF)  1.421241  0.175282\n",
       "3                          Random Forest  1.184066  0.427571\n",
       "4                                    MLP  1.259279  0.352538"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data processing\n",
    "data = pd.read_csv('test_Kd.csv', header=None)\n",
    "data = data.sample(frac=1)\n",
    "X, y = token_simple(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Ridge\n",
    "reg = linear_model.Ridge(alpha=.1)\n",
    "reg = reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "test_rmse_ridge=math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "test_r2_ridge = r2_score(y_test, y_pred)\n",
    "\n",
    "# Lasso\n",
    "clf = linear_model.Lasso(alpha=.1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "test_rmse_lasso=math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "test_r2_lasso = r2_score(y_test, y_pred)\n",
    "\n",
    "# SVM\n",
    "svm = SVR(kernel='rbf',C=1000, gamma=0.1)\n",
    "svm.fit(X_train, y_train)\n",
    "y_test_predicted_svm = svm.predict(X_test)\n",
    "test_rmse_svm = math.sqrt(mean_squared_error(y_test, y_test_predicted_svm))\n",
    "test_r2_svm = r2_score(y_test, y_test_predicted_svm)\n",
    "\n",
    "# Random Forest\n",
    "rnd_forest_reg = RandomForestRegressor(n_estimators=500,  criterion='squared_error',verbose=1, max_depth=20, n_jobs=-1)\n",
    "rnd_forest_reg.fit(X_train, y_train)\n",
    "y_pred = rnd_forest_reg.predict(X_test)\n",
    "test_rmse_rf=math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "test_r2_rf = r2_score(y_test, y_pred)\n",
    "\n",
    "# MLP regressor\n",
    "MLP_reg = MLPRegressor(random_state=1, max_iter=500)\n",
    "MLP_reg.fit(X_train, y_train)\n",
    "y_pred = MLP_reg.predict(X_test)\n",
    "test_rmse_MLP=math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "test_r2_MLP = r2_score(y_test, y_pred)\n",
    "\n",
    "data = [\n",
    "        [\"Ridge Linear Regression\", test_rmse_ridge, test_r2_ridge], \n",
    "        [\"Lasso Linear Regression\", test_rmse_lasso, test_r2_lasso],\n",
    "        [\"Support Vector Machine (Gaussian RBF)\", test_rmse_svm, test_r2_svm],\n",
    "        [\"Random Forest\", test_rmse_rf, test_r2_rf],\n",
    "        [\"MLP\",test_rmse_MLP, test_r2_MLP]\n",
    "       ]\n",
    "\n",
    "\n",
    "pd.DataFrame(data, columns=[\"Model\", \"RMSE\", \"R2 Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa2313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score in SGD: -653568935819211520.000000\n",
      "Optimal Hyperparameter Values in SGD:  {'alpha': 0.1, 'eta0': 0.0001, 'l1_ratio': 0.2, 'learning_rate': 'invscaling', 'max_iter': 400, 'penalty': 'l2'}\n",
      "\n",
      "\n",
      "Root Mean squared error in SGD: 421269225.50\n",
      "Coefficient of determination r^2 variance score [1 is perfect prediction] in SGD: -72458490740040784.00\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# The param_grid tells Scikit-Learn to evaluate all combinations of the hyperparameter values\n",
    "param_grid = {'alpha': [0.1, 0.01, 0.001], 'learning_rate': [\"constant\", \"optimal\", \"invscaling\"], \n",
    "              'l1_ratio': [1, 0.2, 0], 'max_iter':[100, 400, 1000],'eta0': [0.01, 0.001, 0.0001], 'penalty':['l2', 'l1', 'elasticnet']}\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "sgd_cv = GridSearchCV(sgd, param_grid, cv=2, n_jobs=-1)\n",
    "sgd_cv.fit(X_train[:1000], y_train[:1000])\n",
    "\n",
    "params_optimal_sgd = sgd_cv.best_params_\n",
    "\n",
    "print(\"Best Score in SGD: %f\" % sgd_cv.best_score_)\n",
    "print(\"Optimal Hyperparameter Values in SGD: \", params_optimal_sgd)\n",
    "print(\"\\n\")\n",
    "\n",
    "# test the model\n",
    "lin_reg_sgd = SGDRegressor(**params_optimal_sgd)\n",
    "lin_reg_sgd.fit(X_train, y_train)\n",
    "y_test_predicted = lin_reg_sgd.predict(X_test)\n",
    "\n",
    "print(\"Root Mean squared error in SGD: %.2f\" %math.sqrt(mean_squared_error(y_test, y_test_predicted)))\n",
    "print(\"Coefficient of determination r^2 variance score [1 is perfect prediction] in SGD: %.2f\"  % r2_score(y_test, y_test_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd5a0a",
   "metadata": {},
   "source": [
    "### Polynomial degree: used to find out the coefficiency between binding affinity and drugs, which means a particular characteristic among drugs may play a significant role with regards to binding affinity no matter which protein is involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9435276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: (3811,)\n",
      "dataset: (3811, 64)\n",
      "Root Mean squared error for the coefficiency between binding affinity and drugs in SGD: 1.45\n",
      "No. of Original Features:  64\n",
      "No. of Augmented Features:  2145\n",
      "Root Mean squared error for the coefficiency between binding affinity and drugs in polynomial solution: 50.23\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "data = pd.read_csv('test_Kd.csv', header=None)\n",
    "X, y = token_poly(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# SGD Regression\n",
    "lin_reg_sgd = SGDRegressor(max_iter=1000, eta0=0.01, penalty=\"elasticnet\", l1_ratio=0.0, alpha=0.01)\n",
    "lin_reg_sgd.fit(X_train.iloc[:,0:1024], y_train)\n",
    "y_train_predicted = lin_reg_sgd.predict(X_train.iloc[:,:1024])\n",
    "print(\"Root Mean squared error for the coefficiency between binding affinity and drugs in SGD: %.2f\" %math.sqrt(mean_squared_error(y_train, y_train_predicted)))\n",
    "\n",
    "# Add polynomial terms with the feature vector using the sklearn PolynomialFeatures class\n",
    "poly_features = PolynomialFeatures(2)\n",
    "X_train_poly = poly_features.fit_transform(X_train.iloc[:,:1024])\n",
    "print(\"No. of Original Features: \", X_train.iloc[:,:1024].shape[1])\n",
    "print(\"No. of Augmented Features: \", X_train_poly.shape[1])\n",
    "lin_reg_sgd.fit(X_train_poly, y_train)\n",
    "y_train_predicted = lin_reg_sgd.predict(X_train_poly)\n",
    "print(\"Root Mean squared error for the coefficiency between binding affinity and drugs in polynomial solution: %.2f\" %math.sqrt(mean_squared_error(y_train, y_train_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd208df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
